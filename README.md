# ğŸ“Š Earnings Insight Dashboard

This project provides a pipeline to extract, process, and analyze earnings call transcripts using Large Language Models (LLMs). It features a FastAPI backend for data serving and a Streamlit dashboard for interactive visualization of summarized earnings information and extracted insights.

---

## ğŸš€ Features

- **Automated Data Ingestion**: Downloads S&P 500 earnings call transcripts from Hugging Face.
- **Dynamic Transcript Extraction**: Extracts transcripts for a specified ticker symbol.
- **LLM Processing**: Utilizes OpenAI's GPT models (e.g., GPT-4o) to summarize transcripts and extract structured financial insights (EPS, revenue, guidance, key risks, CEO quotes).
- **Data Persistence**: Stores all processed and cleaned LLM outputs into an SQLite database (`data/earnings_insights.db`) for efficient retrieval and querying.
- **FastAPI Backend**: Serves the processed earnings data via a RESTful API.
- **Streamlit Dashboard**: Provides an interactive web interface to explore earnings summaries and insights by company, year, and quarter.
- **Error Handling & Retries**: Includes logic for retrying OpenAI API calls to handle rate limits.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ api/
â”‚   â””â”€â”€ fastapi_server.py         # FastAPI application to serve data from the database.
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ streamlit_app.py          # Streamlit dashboard for data visualization.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Stores all downloaded raw transcripts.
â”‚   â”œâ”€â”€ raw_aapl/                 # Example: stores raw transcripts for a specific ticker (e.g., AAPL).
â”‚   â””â”€â”€ earnings_insights.db      # SQLite database for processed and cleaned data.
â”œâ”€â”€ data_ingestion/
â”‚   â””â”€â”€ phase1_loader.py          # Script to download raw earnings transcripts.
â”œâ”€â”€ llm_processor/
â”‚   â””â”€â”€ phase2_runner.py          # Script to process transcripts with LLMs.
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ clean_outputs.py          # Script to clean LLM outputs (now inserts into DB).
â”‚   â”œâ”€â”€ extract_ticker.py         # Script to extract specific ticker transcripts from raw data.
â”‚   â””â”€â”€ run_all.sh                # Main script to run the entire pipeline.
â”œâ”€â”€ venv/                         # Python virtual environment.
â”œâ”€â”€ .env.example                  # Example environment variables file.
â”œâ”€â”€ .gitignore                    # Specifies intentionally untracked files to ignore.
â”œâ”€â”€ api.log                       # Log file for FastAPI.
â”œâ”€â”€ README.md                     # This README file.
â””â”€â”€ requirements.txt              # Python dependencies.
```

---

## ğŸ› ï¸ Getting Started

### Prerequisites

- Python 3.8+
- Git
- An OpenAI API Key (set as `OPENAI_API_KEY` in your `.env` file)

### 1. Clone the Repository

```bash
git clone <your-repository-url>
cd earnings_insight
```

### 2. Set Up the Python Environment

The `run_all.sh` script will automatically create and activate a virtual environment and install dependencies.

### 3. Configure OpenAI API Key

Create a `.env` file in the project root based on `.env.example`:

```
OPENAI_API_KEY="your_openai_api_key_here"
```

Replace the value with your actual OpenAI API key.

---

## â–¶ï¸ Running the Pipeline

Execute the main shell script to run the entire data processing pipeline, launch the FastAPI server, and open the Streamlit dashboard:

```bash
./scripts/run_all.sh
```

**Note on `TARGET_TICKER`**: By default, the `run_all.sh` script processes `AAPL` transcripts. You can change the `TARGET_TICKER` variable in `scripts/run_all.sh` to process a different company.

**Note on `MAX_WORKERS`**: If you encounter `429 Too Many Requests` errors from OpenAI, reduce the `MAX_WORKERS` variable to a lower value (e.g., `1`) to limit the concurrency of API calls.

---

## ğŸ“Š Using the Dashboard

Once the `run_all.sh` script completes and the Streamlit dashboard opens:

- **Select Company, Year, and Quarter** from the dropdowns.
- **View Summary** of the selected earnings call.
- **Explore Extracted Insights** in a structured table format.

---

## ğŸ“¡ API Endpoints

FastAPI runs on `http://127.0.0.1:8000` and provides:

- `/summary/{ticker}` â€“ Get summary for a specific ticker.
- `/insights/{ticker}` â€“ Get extracted insights for a specific ticker.
- `/company/{ticker}` â€“ Get full record for a specific ticker.
- `/docs` â€“ OpenAPI (Swagger) documentation.

> *Note: Extend endpoints with quarter/year filters as needed.*

---

## ğŸ§¹ Cleanup

To stop services, press `Ctrl+C` in the terminal where `run_all.sh` is running.

To remove generated files:

```bash
rm -rf data/raw data/raw_* data/earnings_insights.db api.log
```

---

## ğŸ¤ Contributing

Feel free to fork the repository, open issues, or submit pull requests.

---

## ğŸ›¡ License

This project is open-source and available under the MIT License.
